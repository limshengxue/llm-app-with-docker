
services:
  web:
    build:
      context: ./api
      dockerfile: Dockerfile
    ports:
      - 8000:8000
    volumes:
      - ./api:/home
    networks:
      - chatbot-net
    environment:
      - OLLAMA_SERVER_URL=http://ollama:11434
      - MODEL_NAME=gemma3:1b
    depends_on:
      ollama:
        condition: service_healthy

  ollama:
    build:
      context: ./ollama
      dockerfile: Dockerfile
    ports:
      - 11434:11434
    volumes:
      - chatbot-vol:/root/.ollama
    networks:
      - chatbot-net
    environment:
      - MODEL_NAME=gemma3:1b
    entrypoint: [ "/usr/bin/bash", "pull-model.sh" ]
    healthcheck:
      test: "bash -c 'cat < /dev/null > /dev/tcp/localhost/11434'"
      interval: 60s
      timeout: 5s
      retries: 5

networks:
  chatbot-net:
    driver: bridge

volumes:
  chatbot-vol:
    driver: local